var documenterSearchIndex = {"docs":
[{"location":"index.html#Slanter","page":"Slanter","title":"Slanter","text":"","category":"section"},{"location":"index.html#Slanter","page":"Slanter","title":"Slanter","text":"Reorder matrices rows and columns to move high values close to the diagonal.\n\nnote: Note\nInstead of providing the limited oclust (like the R version), this includes ehclust, an extended version of [hclust]*https://github.com/JuliaStats/Clustering.jl/blob/master/src/hclust.jl).\n\n\n\n\n\n","category":"module"},{"location":"index.html#Slanter.slanted_orders","page":"Slanter","title":"Slanter.slanted_orders","text":"function slanted_orders(\n    data::AbstractMatrix{<:Real};\n    order_rows::Bool=true,\n    order_cols::Bool=true,\n    squared_order::Bool=true,\n    same_order::Bool=false,\n    discount_outliers::Bool=true,\n    max_spin_count::Integer=10\n)::Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}}\n\nCompute rows and columns orders which move high values close to the diagonal.\n\nFor a matrix expressing the cross-similarity between two (possibly different) sets of entities, this produces better results than clustering. This is because clustering does not care about the order of each two sub-partitions. That is, clustering is as happy with ((2, 1), (4, 3)) as it is with the more sensible ((1, 2), (3, 4)). As a result, visualizations of similarities using naive clustering can be misleading.\n\nThis situation is worse in Python or R than it is in Julia, which mercifully provides the :barjoseph method to reorder the branches. Still, the method here may be \"more suitable\" in specific circumstances (when the data depicts a clear gradient).\n\nParameters\n\ndata: A rectangular matrix containing non-negative values (may be negative if squared_order).\norder_rows: Whether to reorder the rows.\norder_cols: Whether to reorder the columns.\nsquared_order: Whether to reorder to minimize the l2 norm (otherwise minimizes the l1 norm).\nsame_order: Whether to apply the same order to both rows and columns.\ndiscount_outliers: Whether to do a final order phase discounting outlier values far from the diagonal.\nmax_spin_count: How many times to retry improving the solution before giving up.\n\nReturns\n\nA tuple with two vectors, which contain the order of the rows and the columns.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Slanter.slanted_reorder","page":"Slanter","title":"Slanter.slanted_reorder","text":"slanted_reorder(\n    data::AbstractMatrix{T};\n    order_data::Union{AbstractMatrix{<:Real}, Nothing}=nothing,\n    order_rows::Bool=true,\n    order_cols::Bool=true,\n    squared_order::Bool=true,\n    same_order::Bool=false,\n    discount_outliers::Bool=true\n)::AbstractMatrix{T} where {T<:Real}\n\nReorder data rows and columns to move high values close to the diagonal.\n\nGiven a matrix expressing the cross-similarity between two (possibly different) sets of entities, this uses slanted_orders to compute the \"best\" order for visualizing the matrix, then returns the reordered data.\n\nParameters\n\ndata: A rectangular matrix to reorder, of non-negative values (unless order_data is specified, or squared_order)).\norder_data: An optional matrix of non-negative values of the same size to use for computing the orders (may be negative if squared_order).\norder_rows: Whether to reorder the rows.\norder_cols: Whether to reorder the columns.\nsquared_order: Whether to reorder to minimize the l2 norm (otherwise minimizes the l1 norm).\nsame_order: Whether to apply the same order to both rows and columns.\ndiscount_outliers: Whether to do a final order phase discounting outlier values far from the diagonal.\n\nReturns\n\nA matrix of the same shape whose rows and columns are a permutation of the input.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Slanter.reorder_hclust","page":"Slanter","title":"Slanter.reorder_hclust","text":"reorder_hclust(clusters, order)\n\nGiven a clustering of some data, and some ideal order we'd like to use to visualize it, reorder (but do not modify) the clustering to be as consistent as possible with this ideal order.\n\nParameters\n\nclusters: The existing clustering of the data.\norder: The ideal order we'd like to see the data in.\n\nReturns\n\nA reordered clustering which is consistent, wherever possible, with the ideal order.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Slanter.EnhancedHclust","page":"Slanter","title":"Slanter.EnhancedHclust","text":"Enhancements of [hclust]*https://github.com/JuliaStats/Clustering.jl/blob/master/src/hclust.jl)\n\n\n\n\n\n","category":"module"},{"location":"index.html#Slanter.EnhancedHclust.ehclust","page":"Slanter","title":"Slanter.EnhancedHclust.ehclust","text":"ehclust(d::AbstractMatrix; [linkage], [uplo], [branchorder], [order]) -> Hclust\n\nEnhanced [hclust]*https://github.com/JuliaStats/Clustering.jl/blob/master/src/hclust.jl). This is similar to hclust with the following extensions:\n\nIf branchorder is a vector of Real numbers, one per leaf, then we reorder the branches so that each leaf position would be as close as possible to its branchorder value. Technically we compute a center of gravity for each node and reorder the tree such that that at each branch, the left sub-tree center of gravity is to the left (lower than) the center of gravity of the right sub-tree.\nIf order is specified, it must be a permutation of the 1:N leaf indices. This will be the final order of the result. If you specify an explicit branchorder, this will modify the result.\n\nusing Test\nusing Distances\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\npositions = rand(10)\nresult = ehclust(distances; branchorder = positions)\nmerges_data = Vector{Tuple{Int32, Float32}}(undef, 9)\nfor merge_index in 1:9\n    left = result.merges[merge_index, 1]\n    if left < 0\n        left_size = 1\n        left_center = positions[-left]\n    else\n        left_size, left_center = merges_data[left]\n    end\n\n    right = result.merges[merge_index, 2]\n    if right < 0\n        right_size = 1\n        right_center = positions[-right]\n    else\n        right_size, right_center = merges_data[right]\n    end\n\n    @test left_center <= right_center\n    merged_size = left_size + right_size\n    merged_center = (left_center * left_size + right_center * right_size) / merged_size\n    merges_data[merge_index] = (merged_size, merged_center)\nend\n\nprintln(\"OK\")\n\n# output\n\nOK\n\nusing Test\nusing Distances\nusing Random\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\norder = collect(1:10)\nshuffle!(order)\nresult = ehclust(distances; order)\n@test result.order == order\nresult = ehclust(distances; branchorder = :r)\nresult = ehclust(distances; branchorder = :r, order)\n@test result.order != order\n\nprintln(\"OK\")\n\n# output\n\nOK\n\n\n\n\n\n","category":"function"},{"location":"index.html#Index","page":"Slanter","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Slanter","title":"Slanter","text":"","category":"page"}]
}
