var documenterSearchIndex = {"docs":
[{"location":"index.html#Slanter","page":"Slanter","title":"Slanter","text":"","category":"section"},{"location":"index.html#Slanter","page":"Slanter","title":"Slanter","text":"Reorder matrices rows and columns to move high values close to the diagonal.\n\nnote: Note\nInstead of providing the limited oclust (like the R version), this includes ehclust, an extended version of [hclust]*https://github.com/JuliaStats/Clustering.jl/blob/master/src/hclust.jl).\n\n\n\n\n\n","category":"module"},{"location":"index.html#Slanter.slanted_orders","page":"Slanter","title":"Slanter.slanted_orders","text":"function slanted_orders(\n    data::AbstractMatrix{<:Real};\n    order_rows::Bool=true,\n    order_cols::Bool=true,\n    squared_order::Bool=true,\n    same_order::Bool=false,\n    discount_outliers::Bool=true,\n    max_spin_count::Integer=10\n)::Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}}\n\nCompute rows and columns orders which move high values close to the diagonal.\n\nFor a matrix expressing the cross-similarity between two (possibly different) sets of entities, this produces better results than clustering. This is because clustering does not care about the order of each two sub-partitions. That is, clustering is as happy with ((2, 1), (4, 3)) as it is with the more sensible ((1, 2), (3, 4)). As a result, visualizations of similarities using naive clustering can be misleading.\n\nThis situation is worse in Python or R than it is in Julia, which mercifully provides the :barjoseph method to reorder the branches. Still, the method here may be \"more suitable\" in specific circumstances (when the data depicts a clear gradient).\n\nParameters\n\ndata: A rectangular matrix containing non-negative values (may be negative if squared_order).\norder_rows: Whether to reorder the rows.\norder_cols: Whether to reorder the columns.\nsquared_order: Whether to reorder to minimize the l2 norm (otherwise minimizes the l1 norm).\nsame_order: Whether to apply the same order to both rows and columns.\ndiscount_outliers: Whether to do a final order phase discounting outlier values far from the diagonal.\nmax_spin_count: How many times to retry improving the solution before giving up.\n\nReturns\n\nA tuple with two vectors, which contain the order of the rows and the columns.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Slanter.slanted_reorder","page":"Slanter","title":"Slanter.slanted_reorder","text":"slanted_reorder(\n    data::AbstractMatrix{T};\n    order_data::Union{AbstractMatrix{<:Real}, Nothing}=nothing,\n    order_rows::Bool=true,\n    order_cols::Bool=true,\n    squared_order::Bool=true,\n    same_order::Bool=false,\n    discount_outliers::Bool=true\n)::AbstractMatrix{T} where {T<:Real}\n\nReorder data rows and columns to move high values close to the diagonal.\n\nGiven a matrix expressing the cross-similarity between two (possibly different) sets of entities, this uses slanted_orders to compute the \"best\" order for visualizing the matrix, then returns the reordered data.\n\nParameters\n\ndata: A rectangular matrix to reorder, of non-negative values (unless order_data is specified, or squared_order)).\norder_data: An optional matrix of non-negative values of the same size to use for computing the orders (may be negative if squared_order).\norder_rows: Whether to reorder the rows.\norder_cols: Whether to reorder the columns.\nsquared_order: Whether to reorder to minimize the l2 norm (otherwise minimizes the l1 norm).\nsame_order: Whether to apply the same order to both rows and columns.\ndiscount_outliers: Whether to do a final order phase discounting outlier values far from the diagonal.\n\nReturns\n\nA matrix of the same shape whose rows and columns are a permutation of the input.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Slanter.reorder_hclust","page":"Slanter","title":"Slanter.reorder_hclust","text":"reorder_hclust(clusters, order)\n\nGiven a clustering of some data, and some ideal order we'd like to use to visualize it, reorder (but do not modify) the clustering to be as consistent as possible with this ideal order.\n\nParameters\n\nclusters: The existing clustering of the data.\norder: The ideal order we'd like to see the data in.\n\nReturns\n\nA reordered clustering which is consistent, wherever possible, with the ideal order.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Slanter.EnhancedHclust","page":"Slanter","title":"Slanter.EnhancedHclust","text":"Enhancements of [hclust]*https://github.com/JuliaStats/Clustering.jl/blob/master/src/hclust.jl)\n\n\n\n\n\n","category":"module"},{"location":"index.html#Slanter.EnhancedHclust.ehclust","page":"Slanter","title":"Slanter.EnhancedHclust.ehclust","text":"ehclust(d::AbstractMatrix; [linkage], [uplo], [branchorder], [order]) -> Hclust\n\nEnhanced [hclust]*https://github.com/JuliaStats/Clustering.jl/blob/master/src/hclust.jl). This is similar to hclust with the following extensions:\n\nIf branchorder is a vector of Real numbers, one per leaf, then we reorder the branches so that each leaf position would be as close as possible to its branchorder value. Technically we compute a center of gravity for each node and reorder the tree such that that at each branch, the left sub-tree center of gravity is to the left (lower than) the center of gravity of the right sub-tree.\nIf order is specified, it must be a permutation of the 1:N leaf indices. This will be the final order of the result; that is, we constrain the tree so that each node covers a continuous range of leaves (by this order). If you specify an explicit branchorder, this will rotate some nodes so the result will no longer be in the specified order, but the tree is still constrained as above.\nIf groups is a vector of strings, then we first cluster all the entries for each group together, then combine the results. This is mutually exclusive with specifying an order.\nIf groups is a vector of integers, they are expected to cover a range 1:N. We again cluster each group separately, and then cluster the groups enforcing them to be in ascending order. Applying branchorder in this case will only reorder branches inside each group, preserving the ascending order between the groups.\n\nThe groups and order parameters are mutually exclusive.\n\nusing Test\nusing Clustering\nusing Distances\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\nresult = hclust(distances)\neresult = ehclust(distances)\n@test result.order == eresult.order\n\nresult = hclust(distances; linkage = :ward)\neresult = ehclust(distances; linkage = :ward)\n@test result.order == eresult.order\n\nprintln(\"OK\")\n\n# output\n\nOK\n\nusing Test\nusing Distances\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\npositions = rand(10)\nresult = ehclust(distances; branchorder = positions)\nmerges_data = Vector{Tuple{Int, Float64}}(undef, 9)\nfor merge_index in 1:9\n    left = result.merges[merge_index, 1]\n    if left < 0\n        left_size = 1\n        left_center = positions[-left]\n    else\n        left_size, left_center = merges_data[left]\n    end\n\n    right = result.merges[merge_index, 2]\n    if right < 0\n        right_size = 1\n        right_center = positions[-right]\n    else\n        right_size, right_center = merges_data[right]\n    end\n\n    @test left_center <= right_center\n    merged_size = left_size + right_size\n    merged_center = (left_center * left_size + right_center * right_size) / merged_size\n    merges_data[merge_index] = (merged_size, merged_center)\nend\n\nprintln(\"OK\")\n\n# output\n\nOK\n\nusing Test\nusing Distances\nusing Random\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\norder = collect(1:10)\nshuffle!(order)\nresult = ehclust(distances; order)\n@test result.order == order\nresult = ehclust(distances; branchorder = :r, order)\n@test result.order != order\n\nprintln(\"OK\")\n\n# output\n\nOK\n\nusing Test\nusing Distances\nusing Random\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\ngroups = [\"A\", \"B\"][rand(1:2, 10)]\nresult = ehclust(distances; groups)\na_indices = findall(groups[result.order] .== \"A\")\nb_indices = findall(groups[result.order] .== \"B\")\n@assert maximum(a_indices) < minimum(b_indices) || maximum(b_indices) < minimum(a_indices)\n\nprintln(\"OK\")\n\n# output\n\nOK\n\nusing Test\nusing Distances\nusing Random\n\ndata = rand(4, 10)\ndistances = pairwise(Euclidean(), data; dims = 2)\n\ngroups = rand(1:2, 10)\nresult = ehclust(distances; groups)\none_indices = findall(groups[result.order] .== 1)\ntwo_indices = findall(groups[result.order] .== 2)\n@assert maximum(one_indices) < minimum(two_indices)\n\ngroups = 3 .- groups\nresult = ehclust(distances; groups)\none_indices = findall(groups[result.order] .== 1)\ntwo_indices = findall(groups[result.order] .== 2)\n@assert maximum(one_indices) < minimum(two_indices)\n\nbresult = ehclust(distances; branchorder = :r, groups)\n@assert bresult.order != result.order\none_indices = findall(groups[bresult.order] .== 1)\ntwo_indices = findall(groups[bresult.order] .== 2)\n@assert maximum(one_indices) < minimum(two_indices)\n\nprintln(\"OK\")\n\n# output\n\nOK\n\n\n\n\n\n","category":"function"},{"location":"index.html#Index","page":"Slanter","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Slanter","title":"Slanter","text":"","category":"page"}]
}
